{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e00c718",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settings\n",
    "\n",
    "PERSPECTIVE_API = None\n",
    "PERSPECTIVE_QUOTA = None\n",
    "\n",
    "# Location of the yearly files containing sentences flagged as hateful by the FB Roberta HS model\n",
    "TARGET_FOLDER = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "afe19ecb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1750_results.csv already exists. Skipping this file.\n",
      "File /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1751_results.csv already exists. Skipping this file.\n",
      "File /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1752_results.csv already exists. Skipping this file.\n",
      "File /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1753_results.csv already exists. Skipping this file.\n",
      "File /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1754_results.csv already exists. Skipping this file.\n",
      "File /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1755_results.csv already exists. Skipping this file.\n",
      "File /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1756_results.csv already exists. Skipping this file.\n",
      "File /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1758_results.csv already exists. Skipping this file.\n",
      "File /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1759_results.csv already exists. Skipping this file.\n",
      "File /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1760_results.csv already exists. Skipping this file.\n",
      "File /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1761_results.csv already exists. Skipping this file.\n",
      "File /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1762_results.csv already exists. Skipping this file.\n",
      "File /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1763_results.csv already exists. Skipping this file.\n",
      "File /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1764_results.csv already exists. Skipping this file.\n",
      "File /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1765_results.csv already exists. Skipping this file.\n",
      "File /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1766_results.csv already exists. Skipping this file.\n",
      "File /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1767_results.csv already exists. Skipping this file.\n",
      "File /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1768_results.csv already exists. Skipping this file.\n",
      "File /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1769_results.csv already exists. Skipping this file.\n",
      "File /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1770_results.csv already exists. Skipping this file.\n",
      "File /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1771_results.csv already exists. Skipping this file.\n",
      "File /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1772_results.csv already exists. Skipping this file.\n",
      "File /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1773_results.csv already exists. Skipping this file.\n",
      "File /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1774_results.csv already exists. Skipping this file.\n",
      "File /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1775_results.csv already exists. Skipping this file.\n",
      "File /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1776_results.csv already exists. Skipping this file.\n",
      "File /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1777_results.csv already exists. Skipping this file.\n",
      "File /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1778_results.csv already exists. Skipping this file.\n",
      "File /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1779_results.csv already exists. Skipping this file.\n",
      "File /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1780_results.csv already exists. Skipping this file.\n",
      "File /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1781_results.csv already exists. Skipping this file.\n",
      "File /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1782_results.csv already exists. Skipping this file.\n",
      "File /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1783_results.csv already exists. Skipping this file.\n",
      "File /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1784_results.csv already exists. Skipping this file.\n",
      "File /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1785_results.csv already exists. Skipping this file.\n",
      "File /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1786_results.csv already exists. Skipping this file.\n",
      "File /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1787_results.csv already exists. Skipping this file.\n",
      "File /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1788_results.csv already exists. Skipping this file.\n",
      "File /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1789_results.csv already exists. Skipping this file.\n",
      "File /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1790_results.csv already exists. Skipping this file.\n",
      "File /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1791_results.csv already exists. Skipping this file.\n",
      "File /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1792_results.csv already exists. Skipping this file.\n",
      "File /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1793_results.csv already exists. Skipping this file.\n",
      "File /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1794_results.csv already exists. Skipping this file.\n",
      "File /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1795_results.csv already exists. Skipping this file.\n",
      "File /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1796_results.csv already exists. Skipping this file.\n",
      "File /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1797_results.csv already exists. Skipping this file.\n",
      "File /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1798_results.csv already exists. Skipping this file.\n",
      "File /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1799_results.csv already exists. Skipping this file.\n",
      "File /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1800_results.csv already exists. Skipping this file.\n",
      "File /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1801_results.csv already exists. Skipping this file.\n",
      "File /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1802_results.csv already exists. Skipping this file.\n",
      "File /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1803_results.csv already exists. Skipping this file.\n",
      "File /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1804_results.csv already exists. Skipping this file.\n",
      "File /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1805_results.csv already exists. Skipping this file.\n",
      "File /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1806_results.csv already exists. Skipping this file.\n",
      "File /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1807_results.csv already exists. Skipping this file.\n",
      "File /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1808_results.csv already exists. Skipping this file.\n",
      "File /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1809_results.csv already exists. Skipping this file.\n",
      "File /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1810_results.csv already exists. Skipping this file.\n",
      "File /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1811_results.csv already exists. Skipping this file.\n",
      "File /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1812_results.csv already exists. Skipping this file.\n",
      "File /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1813_results.csv already exists. Skipping this file.\n",
      "File /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1814_results.csv already exists. Skipping this file.\n",
      "File /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1815_results.csv already exists. Skipping this file.\n",
      "File /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1816_results.csv already exists. Skipping this file.\n",
      "File /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1817_results.csv already exists. Skipping this file.\n",
      "File /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1818_results.csv already exists. Skipping this file.\n",
      "File /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1819_results.csv already exists. Skipping this file.\n",
      "File /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1820_results.csv already exists. Skipping this file.\n",
      "File /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1821_results.csv already exists. Skipping this file.\n",
      "File /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1822_results.csv already exists. Skipping this file.\n",
      "File /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1823_results.csv already exists. Skipping this file.\n",
      "File /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1824_results.csv already exists. Skipping this file.\n",
      "File /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1825_results.csv already exists. Skipping this file.\n",
      "File /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1826_results.csv already exists. Skipping this file.\n",
      "File /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1827_results.csv already exists. Skipping this file.\n",
      "File /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1828_results.csv already exists. Skipping this file.\n",
      "File /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1829_results.csv already exists. Skipping this file.\n",
      "File /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1830_results.csv already exists. Skipping this file.\n",
      "File /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1831_results.csv already exists. Skipping this file.\n",
      "File /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1832_results.csv already exists. Skipping this file.\n",
      "File /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1833_results.csv already exists. Skipping this file.\n",
      "File /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1834_results.csv already exists. Skipping this file.\n",
      "File /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1835_results.csv already exists. Skipping this file.\n",
      "File /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1836_results.csv already exists. Skipping this file.\n",
      "File /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1837_results.csv already exists. Skipping this file.\n",
      "File /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1838_results.csv already exists. Skipping this file.\n",
      "File /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1839_results.csv already exists. Skipping this file.\n",
      "File /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1840_results.csv already exists. Skipping this file.\n",
      "File /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1841_results.csv already exists. Skipping this file.\n",
      "File /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1842_results.csv already exists. Skipping this file.\n",
      "File /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1843_results.csv already exists. Skipping this file.\n",
      "File /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1844_results.csv already exists. Skipping this file.\n",
      "File /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1845_results.csv already exists. Skipping this file.\n",
      "File /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1846_results.csv already exists. Skipping this file.\n",
      "File /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1847_results.csv already exists. Skipping this file.\n",
      "File /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1848_results.csv already exists. Skipping this file.\n",
      "File /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1849_results.csv already exists. Skipping this file.\n",
      "File /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1850_results.csv already exists. Skipping this file.\n",
      "File /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1851_results.csv already exists. Skipping this file.\n",
      "File /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1852_results.csv already exists. Skipping this file.\n",
      "File /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1853_results.csv already exists. Skipping this file.\n",
      "File /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1854_results.csv already exists. Skipping this file.\n",
      "File /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1855_results.csv already exists. Skipping this file.\n",
      "File /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1856_results.csv already exists. Skipping this file.\n",
      "File /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1857_results.csv already exists. Skipping this file.\n",
      "File /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1858_results.csv already exists. Skipping this file.\n",
      "File /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1859_results.csv already exists. Skipping this file.\n",
      "File /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1860_results.csv already exists. Skipping this file.\n",
      "File /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1861_results.csv already exists. Skipping this file.\n",
      "File /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1862_results.csv already exists. Skipping this file.\n",
      "File /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1863_results.csv already exists. Skipping this file.\n",
      "File /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1864_results.csv already exists. Skipping this file.\n",
      "File /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1865_results.csv already exists. Skipping this file.\n",
      "File /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1866_results.csv already exists. Skipping this file.\n",
      "File /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1867_results.csv already exists. Skipping this file.\n",
      "File /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1868_results.csv already exists. Skipping this file.\n",
      "File /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1869_results.csv already exists. Skipping this file.\n",
      "File /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1870_results.csv already exists. Skipping this file.\n",
      "File /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1871_results.csv already exists. Skipping this file.\n",
      "File /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1872_results.csv already exists. Skipping this file.\n",
      "File /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1873_results.csv already exists. Skipping this file.\n",
      "File /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1874_results.csv already exists. Skipping this file.\n",
      "File /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1875_results.csv already exists. Skipping this file.\n",
      "File /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1876_results.csv already exists. Skipping this file.\n",
      "File /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1877_results.csv already exists. Skipping this file.\n",
      "File /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1878_results.csv already exists. Skipping this file.\n",
      "File /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1879_results.csv already exists. Skipping this file.\n",
      "File /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1880_results.csv already exists. Skipping this file.\n",
      "File /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1881_results.csv already exists. Skipping this file.\n",
      "File /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1882_results.csv already exists. Skipping this file.\n",
      "File /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1883_results.csv already exists. Skipping this file.\n",
      "File /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1884_results.csv already exists. Skipping this file.\n",
      "File /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1885_results.csv already exists. Skipping this file.\n",
      "File /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1886_results.csv already exists. Skipping this file.\n",
      "File /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1887_results.csv already exists. Skipping this file.\n",
      "File /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1888_results.csv already exists. Skipping this file.\n",
      "File /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1889_results.csv already exists. Skipping this file.\n",
      "File /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1890_results.csv already exists. Skipping this file.\n",
      "File /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1891_results.csv already exists. Skipping this file.\n",
      "File /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1892_results.csv already exists. Skipping this file.\n",
      "File /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1893_results.csv already exists. Skipping this file.\n",
      "File /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1894_results.csv already exists. Skipping this file.\n",
      "File /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1895_results.csv already exists. Skipping this file.\n",
      "File /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1896_results.csv already exists. Skipping this file.\n",
      "File /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1897_results.csv already exists. Skipping this file.\n",
      "File /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1898_results.csv already exists. Skipping this file.\n",
      "File /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1899_results.csv already exists. Skipping this file.\n",
      "File /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1900_results.csv already exists. Skipping this file.\n",
      "File /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1901_results.csv already exists. Skipping this file.\n",
      "File /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1902_results.csv already exists. Skipping this file.\n",
      "File /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1903_results.csv already exists. Skipping this file.\n",
      "File /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1904_results.csv already exists. Skipping this file.\n",
      "File /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1905_results.csv already exists. Skipping this file.\n",
      "File /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1906_results.csv already exists. Skipping this file.\n",
      "File /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1907_results.csv already exists. Skipping this file.\n",
      "File /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1908_results.csv already exists. Skipping this file.\n",
      "File /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1909_results.csv already exists. Skipping this file.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved results for /mnt/c/Users/larsj/hate_sents_2/results_1910.jsonl to /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1910_results.csv\n",
      "Saved results for /mnt/c/Users/larsj/hate_sents_2/results_1911.jsonl to /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1911_results.csv\n",
      "Saved results for /mnt/c/Users/larsj/hate_sents_2/results_1912.jsonl to /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1912_results.csv\n",
      "Error: 502. Retrying...\n",
      "Error: 502. Retrying...\n",
      "Error: 502. Retrying...\n",
      "Saved results for /mnt/c/Users/larsj/hate_sents_2/results_1913.jsonl to /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1913_results.csv\n",
      "Saved results for /mnt/c/Users/larsj/hate_sents_2/results_1914.jsonl to /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1914_results.csv\n",
      "Saved results for /mnt/c/Users/larsj/hate_sents_2/results_1915.jsonl to /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1915_results.csv\n",
      "Saved results for /mnt/c/Users/larsj/hate_sents_2/results_1916.jsonl to /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1916_results.csv\n",
      "Saved results for /mnt/c/Users/larsj/hate_sents_2/results_1917.jsonl to /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1917_results.csv\n",
      "Saved results for /mnt/c/Users/larsj/hate_sents_2/results_1918.jsonl to /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1918_results.csv\n",
      "Error: 502. Retrying...\n",
      "Saved results for /mnt/c/Users/larsj/hate_sents_2/results_1919.jsonl to /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1919_results.csv\n",
      "Error: 502. Retrying...\n",
      "Saved results for /mnt/c/Users/larsj/hate_sents_2/results_1920.jsonl to /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1920_results.csv\n",
      "Saved results for /mnt/c/Users/larsj/hate_sents_2/results_1921.jsonl to /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1921_results.csv\n",
      "Saved results for /mnt/c/Users/larsj/hate_sents_2/results_1922.jsonl to /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1922_results.csv\n",
      "Saved results for /mnt/c/Users/larsj/hate_sents_2/results_1923.jsonl to /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1923_results.csv\n",
      "Saved results for /mnt/c/Users/larsj/hate_sents_2/results_1924.jsonl to /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1924_results.csv\n",
      "Saved results for /mnt/c/Users/larsj/hate_sents_2/results_1925.jsonl to /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1925_results.csv\n",
      "Saved results for /mnt/c/Users/larsj/hate_sents_2/results_1926.jsonl to /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1926_results.csv\n",
      "Saved results for /mnt/c/Users/larsj/hate_sents_2/results_1927.jsonl to /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1927_results.csv\n",
      "Saved results for /mnt/c/Users/larsj/hate_sents_2/results_1928.jsonl to /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1928_results.csv\n",
      "Saved results for /mnt/c/Users/larsj/hate_sents_2/results_1929.jsonl to /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1929_results.csv\n",
      "Saved results for /mnt/c/Users/larsj/hate_sents_2/results_1930.jsonl to /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1930_results.csv\n",
      "Saved results for /mnt/c/Users/larsj/hate_sents_2/results_1931.jsonl to /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1931_results.csv\n",
      "Saved results for /mnt/c/Users/larsj/hate_sents_2/results_1932.jsonl to /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1932_results.csv\n",
      "Saved results for /mnt/c/Users/larsj/hate_sents_2/results_1933.jsonl to /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1933_results.csv\n",
      "Skipping sentence due to byte size limit: 55110 bytes.\n",
      "Saved results for /mnt/c/Users/larsj/hate_sents_2/results_1934.jsonl to /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1934_results.csv\n",
      "Saved results for /mnt/c/Users/larsj/hate_sents_2/results_1935.jsonl to /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1935_results.csv\n",
      "Saved results for /mnt/c/Users/larsj/hate_sents_2/results_1936.jsonl to /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1936_results.csv\n",
      "Saved results for /mnt/c/Users/larsj/hate_sents_2/results_1937.jsonl to /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1937_results.csv\n",
      "Saved results for /mnt/c/Users/larsj/hate_sents_2/results_1938.jsonl to /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1938_results.csv\n",
      "Saved results for /mnt/c/Users/larsj/hate_sents_2/results_1939.jsonl to /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1939_results.csv\n",
      "Saved results for /mnt/c/Users/larsj/hate_sents_2/results_1940.jsonl to /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1940_results.csv\n",
      "Saved results for /mnt/c/Users/larsj/hate_sents_2/results_1941.jsonl to /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1941_results.csv\n",
      "Saved results for /mnt/c/Users/larsj/hate_sents_2/results_1942.jsonl to /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1942_results.csv\n",
      "Saved results for /mnt/c/Users/larsj/hate_sents_2/results_1943.jsonl to /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1943_results.csv\n",
      "Saved results for /mnt/c/Users/larsj/hate_sents_2/results_1944.jsonl to /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1944_results.csv\n",
      "Saved results for /mnt/c/Users/larsj/hate_sents_2/results_1945.jsonl to /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1945_results.csv\n",
      "Saved results for /mnt/c/Users/larsj/hate_sents_2/results_1946.jsonl to /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1946_results.csv\n",
      "Saved results for /mnt/c/Users/larsj/hate_sents_2/results_1947.jsonl to /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1947_results.csv\n",
      "Saved results for /mnt/c/Users/larsj/hate_sents_2/results_1948.jsonl to /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1948_results.csv\n",
      "Saved results for /mnt/c/Users/larsj/hate_sents_2/results_1949.jsonl to /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1949_results.csv\n",
      "Saved results for /mnt/c/Users/larsj/hate_sents_2/results_1950.jsonl to /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1950_results.csv\n",
      "Saved results for /mnt/c/Users/larsj/hate_sents_2/results_1951.jsonl to /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1951_results.csv\n",
      "Saved results for /mnt/c/Users/larsj/hate_sents_2/results_1952.jsonl to /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1952_results.csv\n",
      "Saved results for /mnt/c/Users/larsj/hate_sents_2/results_1953.jsonl to /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1953_results.csv\n",
      "Saved results for /mnt/c/Users/larsj/hate_sents_2/results_1954.jsonl to /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1954_results.csv\n",
      "Saved results for /mnt/c/Users/larsj/hate_sents_2/results_1955.jsonl to /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1955_results.csv\n",
      "Saved results for /mnt/c/Users/larsj/hate_sents_2/results_1956.jsonl to /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1956_results.csv\n",
      "Saved results for /mnt/c/Users/larsj/hate_sents_2/results_1957.jsonl to /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1957_results.csv\n",
      "Saved results for /mnt/c/Users/larsj/hate_sents_2/results_1958.jsonl to /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1958_results.csv\n",
      "Saved results for /mnt/c/Users/larsj/hate_sents_2/results_1959.jsonl to /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1959_results.csv\n",
      "Saved results for /mnt/c/Users/larsj/hate_sents_2/results_1960.jsonl to /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1960_results.csv\n",
      "Saved results for /mnt/c/Users/larsj/hate_sents_2/results_1961.jsonl to /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1961_results.csv\n",
      "Saved results for /mnt/c/Users/larsj/hate_sents_2/results_1962.jsonl to /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1962_results.csv\n",
      "Saved results for /mnt/c/Users/larsj/hate_sents_2/results_1963.jsonl to /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1963_results.csv\n",
      "Saved results for /mnt/c/Users/larsj/hate_sents_2/results_1964.jsonl to /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1964_results.csv\n",
      "Saved results for /mnt/c/Users/larsj/hate_sents_2/results_1965.jsonl to /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1965_results.csv\n",
      "Saved results for /mnt/c/Users/larsj/hate_sents_2/results_1966.jsonl to /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1966_results.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved results for /mnt/c/Users/larsj/hate_sents_2/results_1967.jsonl to /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1967_results.csv\n",
      "Saved results for /mnt/c/Users/larsj/hate_sents_2/results_1968.jsonl to /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1968_results.csv\n",
      "Saved results for /mnt/c/Users/larsj/hate_sents_2/results_1969.jsonl to /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1969_results.csv\n",
      "Saved results for /mnt/c/Users/larsj/hate_sents_2/results_1970.jsonl to /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1970_results.csv\n",
      "Saved results for /mnt/c/Users/larsj/hate_sents_2/results_1971.jsonl to /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1971_results.csv\n",
      "Saved results for /mnt/c/Users/larsj/hate_sents_2/results_1972.jsonl to /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1972_results.csv\n",
      "Saved results for /mnt/c/Users/larsj/hate_sents_2/results_1973.jsonl to /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1973_results.csv\n",
      "Saved results for /mnt/c/Users/larsj/hate_sents_2/results_1974.jsonl to /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1974_results.csv\n",
      "Saved results for /mnt/c/Users/larsj/hate_sents_2/results_1975.jsonl to /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1975_results.csv\n",
      "Saved results for /mnt/c/Users/larsj/hate_sents_2/results_1976.jsonl to /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1976_results.csv\n",
      "Saved results for /mnt/c/Users/larsj/hate_sents_2/results_1977.jsonl to /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1977_results.csv\n",
      "Saved results for /mnt/c/Users/larsj/hate_sents_2/results_1978.jsonl to /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1978_results.csv\n",
      "Saved results for /mnt/c/Users/larsj/hate_sents_2/results_1979.jsonl to /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1979_results.csv\n",
      "Saved results for /mnt/c/Users/larsj/hate_sents_2/results_1980.jsonl to /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1980_results.csv\n",
      "Saved results for /mnt/c/Users/larsj/hate_sents_2/results_1981.jsonl to /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1981_results.csv\n",
      "Saved results for /mnt/c/Users/larsj/hate_sents_2/results_1982.jsonl to /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1982_results.csv\n",
      "Saved results for /mnt/c/Users/larsj/hate_sents_2/results_1983.jsonl to /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1983_results.csv\n",
      "Saved results for /mnt/c/Users/larsj/hate_sents_2/results_1984.jsonl to /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1984_results.csv\n",
      "Saved results for /mnt/c/Users/larsj/hate_sents_2/results_1985.jsonl to /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1985_results.csv\n",
      "Saved results for /mnt/c/Users/larsj/hate_sents_2/results_1986.jsonl to /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1986_results.csv\n",
      "Saved results for /mnt/c/Users/larsj/hate_sents_2/results_1987.jsonl to /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1987_results.csv\n",
      "Saved results for /mnt/c/Users/larsj/hate_sents_2/results_1988.jsonl to /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1988_results.csv\n",
      "Saved results for /mnt/c/Users/larsj/hate_sents_2/results_1989.jsonl to /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1989_results.csv\n",
      "Saved results for /mnt/c/Users/larsj/hate_sents_2/results_1990.jsonl to /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1990_results.csv\n",
      "Saved results for /mnt/c/Users/larsj/hate_sents_2/results_1991.jsonl to /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1991_results.csv\n",
      "Saved results for /mnt/c/Users/larsj/hate_sents_2/results_1992.jsonl to /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1992_results.csv\n",
      "Saved results for /mnt/c/Users/larsj/hate_sents_2/results_1993.jsonl to /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1993_results.csv\n",
      "Saved results for /mnt/c/Users/larsj/hate_sents_2/results_1994.jsonl to /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1994_results.csv\n",
      "Saved results for /mnt/c/Users/larsj/hate_sents_2/results_1995.jsonl to /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1995_results.csv\n",
      "Saved results for /mnt/c/Users/larsj/hate_sents_2/results_1996.jsonl to /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1996_results.csv\n",
      "Saved results for /mnt/c/Users/larsj/hate_sents_2/results_1997.jsonl to /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1997_results.csv\n",
      "Saved results for /mnt/c/Users/larsj/hate_sents_2/results_1999.jsonl to /mnt/c/Users/larsj/hate_sents_2/Perspective/results_1999_results.csv\n",
      "Saved results for /mnt/c/Users/larsj/hate_sents_2/results_2000.jsonl to /mnt/c/Users/larsj/hate_sents_2/Perspective/results_2000_results.csv\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import aiohttp\n",
    "import asyncio\n",
    "import math\n",
    "import os\n",
    "import pandas as pd  \n",
    "import nest_asyncio  # Required for Jupyter Notebooks to allow nested asyncio loops\n",
    "from aiohttp import ClientSession\n",
    "\n",
    "# Apply nested asyncio to allow event loop usage in Jupyter\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Define the Google Perspective API URL and your API key\n",
    "API_URL = \"https://commentanalyzer.googleapis.com/v1alpha1/comments:analyze\"\n",
    "API_KEY = PERSPECTIVE_API\n",
    "\n",
    "# Semaphore to control the request rate and avoid exceeding quota (100 requests per second)\n",
    "semaphore = asyncio.Semaphore(PERSPECTIVE_QUOTA)\n",
    "\n",
    "# Asynchronous function to call the Perspective API for a given sentence\n",
    "async def google_perspective_predict_async(session, sentence, max_retries=math.inf):\n",
    "    headers = {\"Content-Type\": \"application/json\"}\n",
    "    payload = {\n",
    "        'comment': {'text': sentence},\n",
    "        'requestedAttributes': {'IDENTITY_ATTACK': {}},\n",
    "        'languages': [\"en\"],\n",
    "    }\n",
    "    params = {'key': API_KEY}\n",
    "\n",
    "    retries = 0\n",
    "    while retries < max_retries:\n",
    "        async with semaphore:\n",
    "            try:\n",
    "                async with session.post(API_URL, headers=headers, params=params, json=payload) as response:\n",
    "                    if response.status == 200:\n",
    "                        result = await response.json()\n",
    "                        return result['attributeScores']['IDENTITY_ATTACK']['summaryScore']['value']\n",
    "                    elif response.status == 429:  # Quota exceeded error\n",
    "                        #print(f\"Quota exceeded: Retrying in {2 ** retries} seconds...\")\n",
    "                        await asyncio.sleep(2 ** retries)  # Exponential backoff\n",
    "                    elif response.status == 400:\n",
    "                        error_message = await response.json()\n",
    "                        # Check if the error is due to text being too long\n",
    "                        if \"Comment text was too many bytes\" in error_message.get('error', {}).get('message', ''):\n",
    "                            print(f\"Skipping sentence due to byte size limit: {len(sentence.encode('utf-8'))} bytes.\")\n",
    "                            return None  # Skip retrying if the text is too long\n",
    "                        print(f\"400 Error: {error_message} for sentence: {sentence}\")\n",
    "                    else:\n",
    "                        print(f\"Error: {response.status}. Retrying...\")\n",
    "                        await asyncio.sleep(1)\n",
    "            except aiohttp.ClientError as e:\n",
    "                print(f\"Request failed: {e}. Retrying...\")\n",
    "                await asyncio.sleep(1)\n",
    "\n",
    "        retries += 1\n",
    "\n",
    "    # If max retries are exceeded, return None\n",
    "    print(f\"Failed to process sentence after {max_retries} retries: {sentence}\")\n",
    "    return None\n",
    "\n",
    "# Asynchronous function to process sentences and save results to a CSV file\n",
    "async def process_file(input_file, output_file):\n",
    "    # Read input JSONL file\n",
    "    with open(input_file, 'r') as infile:\n",
    "        sentences = [json.loads(line) for line in infile]\n",
    "\n",
    "    # Use a single session for all requests\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        tasks = [asyncio.ensure_future(google_perspective_predict_async(session, sentence)) for sentence in sentences]\n",
    "        scores = await asyncio.gather(*tasks)\n",
    "\n",
    "    # Prepare data for CSV\n",
    "    csv_data = [{\"text\": sentence, \"score\": score} for sentence, score in zip(sentences, scores) if score is not None and score > 0.1]\n",
    "\n",
    "    # Save the results to a CSV file\n",
    "    df = pd.DataFrame(csv_data)\n",
    "    df.to_csv(output_file, index=False)\n",
    "    print(f\"Saved results for {input_file} to {output_file}\")\n",
    "\n",
    "# Main function to process all JSONL files in a folder\n",
    "async def main(folder_path):\n",
    "    # Ensure pandas is installed (for saving results to CSV)\n",
    "    try:\n",
    "        import pandas as pd\n",
    "    except ImportError:\n",
    "        print(\"Pandas is not installed. Please install it using `pip install pandas` and run the code again.\")\n",
    "        return\n",
    "\n",
    "    # Iterate through all JSONL files in the specified folder\n",
    "    for filename in os.listdir(folder_path):\n",
    "        output_folder = folder_path + \"/Perspective\"\n",
    "        if filename.endswith(\".jsonl\"):\n",
    "            input_file = os.path.join(folder_path, filename)\n",
    "            output_file = os.path.join(output_folder, filename.replace(\".jsonl\", \"_results.csv\"))\n",
    "            \n",
    "            # Check if the output file already exists\n",
    "            if os.path.exists(output_file):\n",
    "                print(f\"File {output_file} already exists. Skipping this file.\")\n",
    "                continue\n",
    "            \n",
    "            # Process each file and save results to CSV\n",
    "            await process_file(input_file, output_file)\n",
    "\n",
    "# Run the main function using an event loop\n",
    "if __name__ == \"__main__\":\n",
    "    # Replace with your desired folder path\n",
    "    folder_path = TARGET_FOLDER\n",
    "    asyncio.run(main(folder_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f1dd192",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3343433\n",
      "Aggregated None sentences to /mnt/c/Users/larsj/hate_sents_2/roberta_hatefull_all.txt.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import aiohttp\n",
    "import asyncio\n",
    "import math\n",
    "import os\n",
    "import pandas as pd  # Import pandas for CSV saving\n",
    "import nest_asyncio  # Required for Jupyter Notebooks to allow nested asyncio loops\n",
    "from aiohttp import ClientSession\n",
    "\n",
    "all_sentences = []\n",
    "\n",
    "# Asynchronous function to process sentences and save results to a CSV file\n",
    "def process_file(input_file, output_file):\n",
    "    with open(input_file, 'r') as infile:\n",
    "        sentences = [json.loads(line) for line in infile]\n",
    "    \n",
    "    return sentences\n",
    "\n",
    "\n",
    "output_folder = TARGET_FOLDER\n",
    "output_file = os.path.join(output_folder, \"roberta_hatefull_all.txt\")\n",
    "# Iterate through all JSONL files in the specified folder\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith(\".jsonl\"):\n",
    "        input_file = os.path.join(folder_path, filename)\n",
    "        # Process each file and save results to CSV\n",
    "        all_sentences.extend(process_file(input_file, output_file))\n",
    "\n",
    "size = len(all_sentences)\n",
    "\n",
    "# Write the collected sentences to the output text file\n",
    "with open(output_file, 'w', encoding='utf-8') as outfile:\n",
    "    for sentence in all_sentences:\n",
    "        outfile.write(sentence + \"\\n\")\n",
    "\n",
    "print(f\"Aggregated {size} sentences to {output_file}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "50001370",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping results_1758_results.csv as it contains no columns to parse.\n",
      "Skipping results_1984_results.csv as it contains no columns to parse.\n",
      "Skipping results_1991_results.csv as it contains no columns to parse.\n",
      "Skipping results_1999_results.csv as it contains no columns to parse.\n",
      "Aggregated 11 sentences with score >= 0.9 to /mnt/c/Users/larsj/hate_sents_2/Perspective/Thresholds/aggregated_sentences_above_0_9.txt.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Define the folder containing the results CSV files\n",
    "results_folder = f\"{TARGET_FOLDER}/Perspective\"\n",
    "\n",
    "# Define a variable threshold that can be set to control filtering\n",
    "score_threshold = 0.9\n",
    "\n",
    "# Construct the output file name dynamically based on the threshold value\n",
    "output_folder = os.path.join(results_folder, \"Thresholds\")\n",
    "os.makedirs(output_folder, exist_ok=True)  # Ensure the output folder exists\n",
    "output_txt_file = os.path.join(output_folder, f\"aggregated_sentences_above_{str(score_threshold).replace('.', '_')}.txt\")\n",
    "\n",
    "# Initialize a list to store sentences with scores >= the defined threshold\n",
    "sentences_above_threshold = []\n",
    "\n",
    "# Loop through all files in the results folder\n",
    "for filename in os.listdir(results_folder):\n",
    "    if filename.endswith(\"_results.csv\"):  # Only process results CSV files\n",
    "        file_path = os.path.join(results_folder, filename)\n",
    "        \n",
    "        try:\n",
    "            # Read the CSV file into a DataFrame\n",
    "            df = pd.read_csv(file_path)\n",
    "        except pd.errors.EmptyDataError:\n",
    "            print(f\"Skipping {filename} as it contains no columns to parse.\")\n",
    "            continue\n",
    "            \n",
    "        # Check if the required columns exist in the CSV\n",
    "        if 'text' in df.columns and 'score' in df.columns:\n",
    "            # Filter sentences with score >= the specified threshold\n",
    "            high_score_sentences = df[df['score'] >= score_threshold]['text'].tolist()\n",
    "            sentences_above_threshold.extend(high_score_sentences)\n",
    "        else:\n",
    "            print(f\"Skipping {filename} as it doesn't contain the expected columns.\")\n",
    "\n",
    "# Write the collected sentences to the dynamically named output text file\n",
    "with open(output_txt_file, 'w', encoding='utf-8') as outfile:\n",
    "    for sentence in sentences_above_threshold:\n",
    "        outfile.write(sentence + \"\\n\")\n",
    "\n",
    "print(f\"Aggregated {len(sentences_above_threshold)} sentences with score >= {score_threshold} to {output_txt_file}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f963c49e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping 1758 as it contains no columns to parse.\n",
      "Skipping 1984 as it contains no columns to parse.\n",
      "Skipping 1991 as it contains no columns to parse.\n",
      "Skipping 1999 as it contains no columns to parse.\n",
      "Filtered results saved to /mnt/c/Users/larsj/hate_sents_2/Perspective/Datasets/aggregated_sentences_above_0_5.jsonl\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "def filter_sentences_by_threshold(input_folder, output_file, threshold):\n",
    "    # List to store the filtered JSON objects\n",
    "    json_lines = []\n",
    "\n",
    "    # Iterate through all files in the folder\n",
    "    for filename in os.listdir(input_folder):\n",
    "        if filename.startswith(\"results_\") and filename.endswith(\"_results.csv\"):\n",
    "            # Extract the year from the filename\n",
    "            year = filename.split('_')[1]\n",
    "\n",
    "            # Read the CSV file\n",
    "            file_path = os.path.join(input_folder, filename)\n",
    "            try:\n",
    "                # Read the CSV file into a DataFrame\n",
    "                df = pd.read_csv(file_path)\n",
    "            except pd.errors.EmptyDataError:\n",
    "                print(f\"Skipping {year} as it contains no columns to parse.\")\n",
    "                continue\n",
    "\n",
    "            # Filter rows where the score exceeds the threshold\n",
    "            filtered_df = df[df['score'] >= threshold]\n",
    "\n",
    "            # If there are any rows that match the criteria, create a JSON object for that year\n",
    "            if not filtered_df.empty:\n",
    "                json_object = {\n",
    "                    \"year\": int(year),\n",
    "                    \"text\": filtered_df['text'].tolist()  # Convert text column to list\n",
    "                }\n",
    "                # Append the JSON object to the list\n",
    "                json_lines.append(json_object)\n",
    "\n",
    "    # Write the JSON objects to the output file in JSON Lines format\n",
    "    with open(output_file, 'w') as outfile:\n",
    "        for entry in json_lines:\n",
    "            json.dump(entry, outfile)\n",
    "            outfile.write('\\n')\n",
    "\n",
    "    print(f\"Filtered results saved to {output_file}\")\n",
    "\n",
    "threshold = 0.5  # Set the threshold for filtering\n",
    "\n",
    "\n",
    "input_folder = f\"{TARGET_FOLDER}/Perspective\"\n",
    "# Construct the output file name dynamically based on the threshold value\n",
    "output_folder = os.path.join(results_folder, \"Datasets\")\n",
    "os.makedirs(output_folder, exist_ok=True)  # Ensure the output folder exists\n",
    "output_file = os.path.join(output_folder, f\"aggregated_sentences_above_{str(threshold).replace('.', '_')}.jsonl\")\n",
    "\n",
    "filter_sentences_by_threshold(input_folder, output_file, threshold)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "49b29f77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assigning 1758 0 values as it contains no columns to parse.\n",
      "Assigning 1984 0 values as it contains no columns to parse.\n",
      "Assigning 1991 0 values as it contains no columns to parse.\n",
      "Assigning 1999 0 values as it contains no columns to parse.\n",
      "saved statistics to /mnt/c/Users/larsj/hate_sents_2/Perspective/perspective_api_yearly_stats.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Threshold 0.1</th>\n",
       "      <th>Threshold 0.2</th>\n",
       "      <th>Threshold 0.3</th>\n",
       "      <th>Threshold 0.4</th>\n",
       "      <th>Threshold 0.5</th>\n",
       "      <th>Threshold 0.6</th>\n",
       "      <th>Threshold 0.7</th>\n",
       "      <th>Threshold 0.8</th>\n",
       "      <th>Threshold 0.9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1750</td>\n",
       "      <td>69</td>\n",
       "      <td>40</td>\n",
       "      <td>22</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1751</td>\n",
       "      <td>145</td>\n",
       "      <td>80</td>\n",
       "      <td>44</td>\n",
       "      <td>16</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1752</td>\n",
       "      <td>18</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1753</td>\n",
       "      <td>225</td>\n",
       "      <td>122</td>\n",
       "      <td>62</td>\n",
       "      <td>31</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1754</td>\n",
       "      <td>46</td>\n",
       "      <td>26</td>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>1995</td>\n",
       "      <td>25</td>\n",
       "      <td>18</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>1996</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>1997</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>1999</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>2000</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>249 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Year  Threshold 0.1  Threshold 0.2  Threshold 0.3  Threshold 0.4  \\\n",
       "0    1750             69             40             22             14   \n",
       "1    1751            145             80             44             16   \n",
       "2    1752             18             10              8              3   \n",
       "3    1753            225            122             62             31   \n",
       "4    1754             46             26             13              7   \n",
       "..    ...            ...            ...            ...            ...   \n",
       "244  1995             25             18              7              4   \n",
       "245  1996             16              6              2              2   \n",
       "246  1997              4              2              0              0   \n",
       "247  1999              0              0              0              0   \n",
       "248  2000              6              3              1              0   \n",
       "\n",
       "     Threshold 0.5  Threshold 0.6  Threshold 0.7  Threshold 0.8  Threshold 0.9  \n",
       "0                6              4              0              0              0  \n",
       "1                7              2              0              0              0  \n",
       "2                1              0              0              0              0  \n",
       "3               15              6              1              0              0  \n",
       "4                2              0              0              0              0  \n",
       "..             ...            ...            ...            ...            ...  \n",
       "244              2              0              0              0              0  \n",
       "245              0              0              0              0              0  \n",
       "246              0              0              0              0              0  \n",
       "247              0              0              0              0              0  \n",
       "248              0              0              0              0              0  \n",
       "\n",
       "[249 rows x 10 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create statistics about number of hateful senteces for different perspective API thresholds\n",
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "def perspective_stats_by_threshold(input_folder, output_file):\n",
    "    # All threshold values\n",
    "    thresholds = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    # Iterate through all files in the folder\n",
    "    for filename in os.listdir(input_folder):\n",
    "        if filename.startswith(\"results_\") and filename.endswith(\"_results.csv\"):\n",
    "            # Extract the year from the filename\n",
    "            year = filename.split('_')[1]\n",
    "            # Read the CSV file\n",
    "            file_path = os.path.join(input_folder, filename)\n",
    "            \n",
    "            results[year] = {}\n",
    "            try:\n",
    "                # Read the CSV file into a DataFrame\n",
    "                df = pd.read_csv(file_path)\n",
    "            except pd.errors.EmptyDataError:\n",
    "                print(f\"Assigning {year} 0 values as it contains no columns to parse.\")\n",
    "                for threshold in thresholds:\n",
    "                    results[year][threshold] = 0\n",
    "                continue\n",
    "                \n",
    "            \n",
    "            for threshold in thresholds:\n",
    "                count = (df['score'] >= threshold).sum()\n",
    "                results[year][threshold] = count\n",
    "                \n",
    "    # Convert the dictionary to a pandas DataFrame\n",
    "    df = pd.DataFrame(results).T  # Transpose to make years rows and thresholds columns\n",
    "    df.columns = [f\"Threshold {t}\" for t in thresholds]  # Rename columns for readability\n",
    "    # Reset index to make the 'Year' column and set it as the first column\n",
    "    df.reset_index(inplace=True)\n",
    "    df.rename(columns={'index': 'Year'}, inplace=True)\n",
    "    print(f\"saved statistics to {output_file}\")\n",
    "    stats_df.to_csv(output_file)\n",
    "        \n",
    "    return df\n",
    "\n",
    "threshold = 0.5  # Set the threshold for filtering\n",
    "\n",
    "\n",
    "input_folder = f\"{TARGET_FOLDER}/Perspective\"\n",
    "output_folder = input_folder\n",
    "os.makedirs(output_folder, exist_ok=True)  # Ensure the output folder exists\n",
    "output_file = os.path.join(output_folder, f\"perspective_api_yearly_stats.csv\")\n",
    "\n",
    "stats_df = perspective_stats_by_threshold(input_folder, output_file)\n",
    "display(stats_df)\n",
    "stats_df.to_csv(output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a11a0f90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled sentences saved to /mnt/c/Users/larsj/hate_sents_2/Perspective/Thresholds/0_6_sample_chunk.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "# Set a seed for reproducibility\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "\n",
    "threshold = 0.6\n",
    "\n",
    "# Define file paths\n",
    "input_file = f\"{TARGET_FOLDER}/Perspective/Thresholds/aggregated_sentences_above_{str(treshold).replace('.', '_')}.txt\"  # Input file containing sentences\n",
    "output_file = f\"{TARGET_FOLDER}/Perspective/Thresholds/{str(treshold).replace('.', '_')}_sample_chunk.csv\"  # Output CSV file\n",
    "\n",
    "# Read sentences from the input file\n",
    "with open(input_file, 'r') as file:\n",
    "    sentences = file.readlines()\n",
    "\n",
    "# Remove any trailing newlines\n",
    "sentences = [sentence.strip() for sentence in sentences]\n",
    "\n",
    "# Calculate the number of sentences in each chunk\n",
    "num_sentences = len(sentences)\n",
    "chunk_size = num_sentences // 100\n",
    "\n",
    "# Split sentences into 100 equal chunks\n",
    "chunks = [sentences[i * chunk_size: (i + 1) * chunk_size] for i in range(100)]\n",
    "\n",
    "# Draw one random sample from each chunk\n",
    "samples = [random.choice(chunk) for chunk in chunks]\n",
    "\n",
    "# Create a DataFrame to store the samples\n",
    "df = pd.DataFrame({\n",
    "    \"sentence\": samples,\n",
    "    \"hateful\": [''] * len(samples)  # Empty column for 'hateful'\n",
    "})\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Sampled sentences saved to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3bd9cd21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping results_1758_results.csv as it contains no columns to parse.\n",
      "Skipping results_1984_results.csv as it contains no columns to parse.\n",
      "Skipping results_1991_results.csv as it contains no columns to parse.\n",
      "Skipping results_1999_results.csv as it contains no columns to parse.\n",
      "Aggregated 148038 sentences with score >= 0.3 to /mnt/c/Users/larsj/hate_sents_2/Perspective/Thresholds/aggregated_sentences_above_0_3_delta.txt.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Define the folder containing the results CSV files\n",
    "results_folder = f\"{TARGET_FOLDER}/Perspective\"\n",
    "\n",
    "# Define a variable threshold that can be set to control filtering\n",
    "score_threshold = 0.3\n",
    "upper_threshold = score_threshold + 0.1\n",
    "\n",
    "# Construct the output file name dynamically based on the threshold value\n",
    "output_folder = os.path.join(results_folder, \"Thresholds\")\n",
    "os.makedirs(output_folder, exist_ok=True)  # Ensure the output folder exists\n",
    "output_txt_file = os.path.join(output_folder, f\"aggregated_sentences_above_{str(score_threshold).replace('.', '_')}_delta.txt\")\n",
    "\n",
    "# Initialize a list to store sentences with scores >= the defined threshold\n",
    "sentences_above_threshold = []\n",
    "\n",
    "# Loop through all files in the results folder\n",
    "for filename in os.listdir(results_folder):\n",
    "    if filename.endswith(\"_results.csv\"):  # Only process results CSV files\n",
    "        file_path = os.path.join(results_folder, filename)\n",
    "        \n",
    "        try:\n",
    "            # Read the CSV file into a DataFrame\n",
    "            df = pd.read_csv(file_path)\n",
    "        except pd.errors.EmptyDataError:\n",
    "            print(f\"Skipping {filename} as it contains no columns to parse.\")\n",
    "            continue\n",
    "            \n",
    "        # Check if the required columns exist in the CSV\n",
    "        if 'text' in df.columns and 'score' in df.columns:\n",
    "            # Filter sentences with score >= the specified threshold\n",
    "            high_score_sentences = df[(df['score'] >= score_threshold) & (df['score'] < upper_threshold)]['text'].tolist()\n",
    "            sentences_above_threshold.extend(high_score_sentences)\n",
    "        else:\n",
    "            print(f\"Skipping {filename} as it doesn't contain the expected columns.\")\n",
    "\n",
    "# Write the collected sentences to the dynamically named output text file\n",
    "with open(output_txt_file, 'w', encoding='utf-8') as outfile:\n",
    "    for sentence in sentences_above_threshold:\n",
    "        outfile.write(sentence + \"\\n\")\n",
    "\n",
    "print(f\"Aggregated {len(sentences_above_threshold)} sentences with score >= {score_threshold} and score < {score_threshold+0.1} to {output_txt_file}.\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
